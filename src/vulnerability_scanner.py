import langchain_openai
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from status_logger import logger

from dotenv import load_dotenv
load_dotenv()


def code_scanner(code_chunks, persist_dir, db_collection_name):
    suggestions = []
    for chunk in code_chunks:
        if not chunk.get("code"):
            continue
        
        query = extract_query(chunk)
        if not query:
            continue

        doc = test_retrieval(persist_dir, query)
        if doc:

            secure_practices = doc.metadata.get("Secure Coding Practices", "No secure practices found.")
            references = doc.metadata.get("References", "No references found.")

            suggestion = llm_query(chunk["code"],chunk["metadata"], doc.metadata.get("Vulnerability Name", "Unknown"), secure_practices, references)
            if suggestion:
                suggestions.append({
                    "start_line": chunk["start_line"],
                    "end_line": chunk["end_line"],
                    "vulnerability_name": doc.metadata.get("Vulnerability Name", "Unknown"),
                    "suggestion": suggestion,
                    "secure_practices": secure_practices,
                    "references": references
                })

        else:
            logger("debug", "No relevant document found for this code snippet.")

    return suggestions

def extract_query(chunk):
    if not chunk.get("code", None):
        return None
    
    code = chunk["code"].strip()
    if not code:
        return None
    
    return code

def test_retrieval(persist_dir, query, k=1):
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small" 
    )
    db = Chroma(
        embedding_function=embeddings,
        persist_directory=persist_dir,
        collection_name='vulns_insecure'
    )

    doc_and_score = db.similarity_search_with_score(query, k=k)

    if not doc_and_score:
        logger("info", "No relevant documents found for the query.")
        return
    
    doc, score = doc_and_score[0]


    return doc

def llm_query(code, metadata, vulnerability_name, secure_practices, references):
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.0,
    )

    return 